# –ü–ª–∞–Ω –ø–æ—ç—Ç–∞–ø–Ω–æ–π –º–∏–≥—Ä–∞—Ü–∏–∏ –≥—Ä—É–∑–∏–Ω—Å–∫–æ–π –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–π —Å–∏—Å—Ç–µ–º—ã

## üéØ –û–±—â–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏

**–ü–æ–¥—Ö–æ–¥**: Strangler Fig Pattern - –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–∞—è –∑–∞–º–µ–Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –±–µ–∑ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã

**–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: 18-24 –º–µ—Å—è—Ü–∞

**–ë—é–¥–∂–µ—Ç**: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ—ç—Ç–∞–ø–Ω–æ –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∏—Å–∫–æ–≤

---

## üìã –§–∞–∑–∞ 0: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ (–ú–µ—Å—è—Ü—ã 1-2)

### –¶–µ–ª–∏:
- –ê—É–¥–∏—Ç —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
- –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –º–∏–≥—Ä–∞—Ü–∏–∏

### –ó–∞–¥–∞—á–∏:

#### –ù–µ–¥–µ–ª—è 1-2: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞—É–¥–∏—Ç
```bash
# –ê–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
- –ò–Ω–≤–µ–Ω—Ç–∞—Ä–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- –û—Ü–µ–Ω–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è (—Ç–µ–∫—É—â–∏–π: ~10%, —Ü–µ–ª—å: 85%)
- –í—ã—è–≤–ª–µ–Ω–∏–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —É–∑–∫–∏—Ö –º–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
- –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö: –æ–±—ä–µ–º—ã, —Å—Ç—Ä—É–∫—Ç—É—Ä–∞, quality issues
```

#### –ù–µ–¥–µ–ª—è 3-4: –°–æ–∑–¥–∞–Ω–∏–µ MVP –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
```yaml
# docker-compose-migration.yml
version: '3.8'
services:
  # –¢–µ–∫—É—â–∞—è —Å–∏—Å—Ç–µ–º–∞ (legacy)
  legacy-app:
    build: ./legacy
    ports:
      - "8080:8080"
    networks:
      - migration-network
  
  # –ù–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ (target)
  new-api-gateway:
    build: ./new-system/gateway
    ports:
      - "8000:8000"
    networks:
      - migration-network
  
  # Shared resources
  postgres-new:
    image: postgres:15
    environment:
      POSTGRES_DB: accounting_new
    networks:
      - migration-network
  
  redis:
    image: redis:7-alpine
    networks:
      - migration-network

networks:
  migration-network:
    driver: bridge
```

#### –ù–µ–¥–µ–ª—è 5-6: –°–æ–∑–¥–∞–Ω–∏–µ Data Pipeline
```python
# migration/data_sync.py
from sqlalchemy import create_engine
import asyncpg
import pandas as pd

class DataSynchronizer:
    def __init__(self):
        self.legacy_engine = create_engine('postgresql://legacy_db')
        self.new_pool = None
    
    async def sync_accounts(self):
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ —Å—á–µ—Ç–æ–≤"""
        df = pd.read_sql("SELECT * FROM chart_of_accounts", self.legacy_engine)
        
        # Transform data
        df['id'] = df.apply(lambda x: uuid4(), axis=1)
        df['created_at'] = pd.Timestamp.now()
        
        # Load to new system
        async with self.new_pool.acquire() as conn:
            await conn.executemany(
                "INSERT INTO accounts (id, code, name, type) VALUES ($1, $2, $3, $4)",
                df[['id', 'code', 'name', 'account_type']].values.tolist()
            )
```

#### –ù–µ–¥–µ–ª—è 7-8: CI/CD Pipeline
```yaml
# .github/workflows/migration.yml
name: Migration Pipeline
on:
  push:
    branches: [main, migration/*]

jobs:
  test-legacy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Test Legacy System
        run: |
          docker-compose -f legacy/docker-compose.test.yml up --abort-on-container-exit
  
  test-new-system:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Test New System
        run: |
          docker-compose -f new-system/docker-compose.test.yml up --abort-on-container-exit
  
  deploy-staging:
    needs: [test-legacy, test-new-system]
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to Staging
        run: |
          kubectl apply -f k8s/staging/
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –§–∞–∑—ã 0:
- ‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ —Ä–∞–º–∫–∞–º–∏
- ‚úÖ –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º
- ‚úÖ –ö–æ–º–∞–Ω–¥–∞ –≥–æ—Ç–æ–≤–∞ –∫ –º–∏–≥—Ä–∞—Ü–∏–∏ (3-5 —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤)
- ‚úÖ –ë–∞–∑–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –∞–ª–µ—Ä—Ç–æ–≤

---

## üîß –§–∞–∑–∞ 1: –ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞ (–ú–µ—Å—è—Ü—ã 3-6)

### –¶–µ–ª–∏:
- –ó–∞–º–µ–Ω–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- –ü–æ–≤—ã—à–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
- –£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### 1.1 –ú–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–ú–µ—Å—è—Ü 3)

#### –ù–µ–¥–µ–ª—è 1-2: –ù–æ–≤–∞—è —Å—Ö–µ–º–∞ –ë–î
```sql
-- migrations/001_new_schema.sql
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_stat_statements";

-- –ù–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å—á–µ—Ç–æ–≤ —Å UUID
CREATE TABLE accounts_v2 (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    code VARCHAR(20) NOT NULL,
    name VARCHAR(100) NOT NULL,
    account_type account_type_enum NOT NULL,
    parent_id UUID REFERENCES accounts_v2(id),
    is_active BOOLEAN DEFAULT TRUE,
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    version INTEGER DEFAULT 1,
    
    -- –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    CONSTRAINT unique_code_per_company UNIQUE (code, company_id)
);

CREATE INDEX idx_accounts_v2_code ON accounts_v2(code);
CREATE INDEX idx_accounts_v2_type ON accounts_v2(account_type);
CREATE INDEX idx_accounts_v2_parent ON accounts_v2(parent_id);
```

#### –ù–µ–¥–µ–ª—è 3-4: –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–∞–±–ª–∏—Ü
```sql
-- –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∂—É—Ä–Ω–∞–ª–∞ –ø—Ä–æ–≤–æ–¥–æ–∫ –ø–æ –º–µ—Å—è—Ü–∞–º
CREATE TABLE journal_entries_v2 (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    transaction_id UUID NOT NULL,
    account_id UUID NOT NULL REFERENCES accounts_v2(id),
    debit DECIMAL(15,2) DEFAULT 0.00,
    credit DECIMAL(15,2) DEFAULT 0.00,
    currency_code CHAR(3) NOT NULL DEFAULT 'GEL',
    exchange_rate DECIMAL(15,5) DEFAULT 1.00000,
    description TEXT,
    transaction_date DATE NOT NULL,
    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT check_debit_credit CHECK (
        (debit > 0 AND credit = 0) OR (credit > 0 AND debit = 0)
    )
) PARTITION BY RANGE (transaction_date);

-- –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞—Ä—Ç–∏—Ü–∏–π –Ω–∞ –≥–æ–¥ –≤–ø–µ—Ä–µ–¥
CREATE TABLE journal_entries_202501 PARTITION OF journal_entries_v2
    FOR VALUES FROM ('2025-01-01') TO ('2025-02-01');
-- ... –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Å—è—Ü—ã
```

### 1.2 –ù–æ–≤—ã–π API —Å–ª–æ–π (–ú–µ—Å—è—Ü 4)

#### FastAPI —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º–∏
```python
# new_system/api/main.py
from fastapi import FastAPI, Depends, HTTPException, BackgroundTasks
from fastapi.security import HTTPBearer
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import structlog

logger = structlog.get_logger()

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    await init_database_pool()
    await init_kafka_producer()
    logger.info("Application started")
    
    yield
    
    # Shutdown
    await close_database_pool()
    await close_kafka_producer()
    logger.info("Application stopped")

app = FastAPI(
    title="Georgian Accounting System v2.0",
    description="Modern IFRS-compliant accounting system",
    version="2.0.0",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure properly in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# API Routes
from .routes import accounts, transactions, reports

app.include_router(accounts.router, prefix="/api/v1/accounts")
app.include_router(transactions.router, prefix="/api/v1/transactions")
app.include_router(reports.router, prefix="/api/v1/reports")
```

#### –°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å DI
```python
# new_system/core/dependencies.py
from dependency_injector import containers, providers
from dependency_injector.wiring import Provide

class Container(containers.DeclarativeContainer):
    # Configuration
    config = providers.Configuration()
    
    # Database
    db_pool = providers.Singleton(
        create_async_pool,
        config.database.url
    )
    
    # Repositories
    account_repository = providers.Factory(
        AccountRepository,
        db_pool=db_pool
    )
    
    transaction_repository = providers.Factory(
        TransactionRepository,
        db_pool=db_pool
    )
    
    # Services
    accounting_service = providers.Factory(
        AccountingService,
        account_repo=account_repository,
        transaction_repo=transaction_repository
    )

# Dependency injection
async def get_accounting_service(
    service: AccountingService = Depends(Provide[Container.accounting_service])
) -> AccountingService:
    return service
```

### 1.3 –°–∏—Å—Ç–µ–º–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (–ú–µ—Å—è—Ü 5)

#### JWT —Å refresh tokens
```python
# new_system/auth/jwt_handler.py
from jose import JWTError, jwt
from datetime import datetime, timedelta
import secrets

class JWTHandler:
    def __init__(self, secret_key: str):
        self.secret_key = secret_key
        self.algorithm = "HS256"
        self.access_token_expire = timedelta(minutes=30)
        self.refresh_token_expire = timedelta(days=7)
    
    async def create_tokens(self, user_id: str, permissions: List[str]) -> TokenPair:
        access_payload = {
            "sub": user_id,
            "permissions": permissions,
            "type": "access",
            "exp": datetime.utcnow() + self.access_token_expire,
            "iat": datetime.utcnow(),
            "jti": secrets.token_hex(16)  # JWT ID –¥–ª—è –æ—Ç–∑—ã–≤–∞
        }
        
        refresh_payload = {
            "sub": user_id,
            "type": "refresh",
            "exp": datetime.utcnow() + self.refresh_token_expire,
            "iat": datetime.utcnow(),
            "jti": secrets.token_hex(16)
        }
        
        access_token = jwt.encode(access_payload, self.secret_key, self.algorithm)
        refresh_token = jwt.encode(refresh_payload, self.secret_key, self.algorithm)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å refresh token –≤ Redis —Å TTL
        await self.redis.setex(f"refresh:{refresh_payload['jti']}", 
                              int(self.refresh_token_expire.total_seconds()),
                              user_id)
        
        return TokenPair(
            access_token=access_token,
            refresh_token=refresh_token,
            expires_in=int(self.access_token_expire.total_seconds())
        )
```

#### Role-Based Access Control
```python
# new_system/auth/rbac.py
from enum import Enum
from dataclasses import dataclass
from typing import Set

class Permission(Enum):
    ACCOUNTS_READ = "accounts:read"
    ACCOUNTS_WRITE = "accounts:write"
    TRANSACTIONS_READ = "transactions:read"
    TRANSACTIONS_WRITE = "transactions:write"
    TRANSACTIONS_APPROVE = "transactions:approve"
    REPORTS_FINANCIAL = "reports:financial"
    REPORTS_TAX = "reports:tax"
    ADMIN_USERS = "admin:users"
    ADMIN_SYSTEM = "admin:system"

@dataclass
class Role:
    name: str
    permissions: Set[Permission]

class GeorgianAccountingRoles:
    ACCOUNTANT = Role("accountant", {
        Permission.ACCOUNTS_READ,
        Permission.TRANSACTIONS_READ,
        Permission.TRANSACTIONS_WRITE,
        Permission.REPORTS_FINANCIAL
    })
    
    CHIEF_ACCOUNTANT = Role("chief_accountant", {
        *ACCOUNTANT.permissions,
        Permission.TRANSACTIONS_APPROVE,
        Permission.REPORTS_TAX,
        Permission.ADMIN_USERS
    })
    
    TAX_SPECIALIST = Role("tax_specialist", {
        Permission.ACCOUNTS_READ,
        Permission.TRANSACTIONS_READ,
        Permission.REPORTS_TAX
    })

def require_permission(permission: Permission):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, current_user = Depends(get_current_user), **kwargs):
            if permission not in current_user.permissions:
                raise HTTPException(403, "Insufficient permissions")
            return await func(*args, **kwargs, current_user=current_user)
        return wrapper
    return decorator
```

### 1.4 –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ (–ú–µ—Å—è—Ü 6)

#### –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
```python
# new_system/core/logging.py
import structlog
from pythonjsonlogger import jsonlogger

def setup_logging():
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ –∫–æ–¥–µ
logger = structlog.get_logger()

async def create_transaction(transaction_data: TransactionCreate):
    logger.info(
        "Transaction creation started",
        transaction_id=transaction_data.id,
        user_id=current_user.id,
        amount=float(transaction_data.total_amount)
    )
    
    try:
        result = await service.create_transaction(transaction_data)
        logger.info(
            "Transaction created successfully",
            transaction_id=result.id,
            duration_ms=(time.time() - start_time) * 1000
        )
        return result
    except Exception as e:
        logger.error(
            "Transaction creation failed",
            error=str(e),
            transaction_data=transaction_data.dict()
        )
        raise
```

#### Prometheus –º–µ—Ç—Ä–∏–∫–∏
```python
# new_system/core/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# Business metrics
transaction_counter = Counter(
    'accounting_transactions_total',
    'Total number of accounting transactions',
    ['status', 'transaction_type']
)

transaction_amount_histogram = Histogram(
    'accounting_transaction_amount_gel',
    'Distribution of transaction amounts in GEL',
    buckets=[10, 50, 100, 500, 1000, 5000, 10000, 50000, float('inf')]
)

account_balance_gauge = Gauge(
    'accounting_account_balance_gel',
    'Current account balance in GEL',
    ['account_code', 'account_type']
)

# Technical metrics
request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint', 'status']
)

class MetricsMiddleware:
    async def __call__(self, request, call_next):
        start_time = time.time()
        response = await call_next(request)
        duration = time.time() - start_time
        
        request_duration.labels(
            method=request.method,
            endpoint=request.url.path,
            status=response.status_code
        ).observe(duration)
        
        return response
```

### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –§–∞–∑—ã 1:
- ‚úÖ –ù–æ–≤–∞—è –ë–î —Å—Ö–µ–º–∞ —Å UUID –∏ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
- ‚úÖ Modern FastAPI —Å async/await
- ‚úÖ JWT authentication —Å RBAC
- ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–µ—Ç—Ä–∏–∫–∏
- ‚úÖ 60% –ø–æ–∫—Ä—ã—Ç–∏–µ —Ç–µ—Å—Ç–∞–º–∏ –Ω–æ–≤—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

---

## üèóÔ∏è –§–∞–∑–∞ 2: –í–Ω–µ–¥—Ä–µ–Ω–∏–µ Event-Driven Architecture (–ú–µ—Å—è—Ü—ã 7-10)

### –¶–µ–ª–∏:
- –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Event Sourcing –¥–ª—è audit trail
- CQRS –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è —á—Ç–µ–Ω–∏—è/–∑–∞–ø–∏—Å–∏
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Kafka

### 2.1 Event Store –∏ Event Sourcing (–ú–µ—Å—è—Ü 7)

#### Event Store –Ω–∞ PostgreSQL
```sql
-- events/001_event_store.sql
CREATE TABLE event_store (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    aggregate_id UUID NOT NULL,
    aggregate_type VARCHAR(100) NOT NULL,
    event_type VARCHAR(100) NOT NULL,
    event_data JSONB NOT NULL,
    event_metadata JSONB DEFAULT '{}',
    version INTEGER NOT NULL,
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    
    CONSTRAINT unique_version_per_aggregate UNIQUE (aggregate_id, version)
);

CREATE INDEX idx_event_store_aggregate ON event_store(aggregate_id);
CREATE INDEX idx_event_store_type ON event_store(event_type);
CREATE INDEX idx_event_store_timestamp ON event_store(timestamp);

-- Snapshots –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
CREATE TABLE aggregate_snapshots (
    aggregate_id UUID PRIMARY KEY,
    aggregate_type VARCHAR(100) NOT NULL,
    snapshot_data JSONB NOT NULL,
    version INTEGER NOT NULL,
    timestamp TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
```

#### –ë–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã –¥–ª—è Event Sourcing
```python
# new_system/events/base.py
from dataclasses import dataclass
from typing import Any, List, Dict
from abc import ABC, abstractmethod
import uuid
from datetime import datetime

@dataclass(frozen=True)
class DomainEvent:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –¥–æ–º–µ–Ω–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π"""
    aggregate_id: uuid.UUID
    event_id: uuid.UUID
    event_type: str
    event_data: Dict[str, Any]
    version: int
    timestamp: datetime
    metadata: Dict[str, Any]

class Aggregate(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ç–æ–≤"""
    def __init__(self, aggregate_id: uuid.UUID):
        self.id = aggregate_id
        self.version = 0
        self.uncommitted_events: List[DomainEvent] = []
    
    def apply_event(self, event: DomainEvent):
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ –∫ –∞–≥—Ä–µ–≥–∞—Ç—É"""
        self._apply_event(event)
        if event.version > self.version:
            self.version = event.version
    
    def raise_event(self, event_type: str, event_data: Dict[str, Any], metadata: Dict[str, Any] = None):
        """–ü–æ–¥–Ω—è—Ç—å –Ω–æ–≤–æ–µ —Å–æ–±—ã—Ç–∏–µ"""
        event = DomainEvent(
            aggregate_id=self.id,
            event_id=uuid.uuid4(),
            event_type=event_type,
            event_data=event_data,
            version=self.version + 1,
            timestamp=datetime.utcnow(),
            metadata=metadata or {}
        )
        self.uncommitted_events.append(event)
        self.apply_event(event)
    
    @abstractmethod
    def _apply_event(self, event: DomainEvent):
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ –∫ —Å–æ—Å—Ç–æ—è–Ω–∏—é –∞–≥—Ä–µ–≥–∞—Ç–∞"""
        pass
    
    def mark_events_as_committed(self):
        """–ü–æ–º–µ—Ç–∏—Ç—å —Å–æ–±—ã—Ç–∏—è –∫–∞–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ"""
        self.uncommitted_events.clear()
```

#### Accounting Aggregate
```python
# new_system/domain/aggregates.py
from decimal import Decimal
from dataclasses import dataclass
from typing import List, Optional

@dataclass
class JournalEntryData:
    account_id: uuid.UUID
    debit: Decimal
    credit: Decimal
    description: str

class AccountingTransaction(Aggregate):
    """–ê–≥—Ä–µ–≥–∞—Ç –±—É—Ö–≥–∞–ª—Ç–µ—Ä—Å–∫–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
    
    def __init__(self, aggregate_id: uuid.UUID):
        super().__init__(aggregate_id)
        self.transaction_date: Optional[datetime] = None
        self.description: str = ""
        self.entries: List[JournalEntryData] = []
        self.status: str = "draft"
        self.total_debit: Decimal = Decimal('0.00')
        self.total_credit: Decimal = Decimal('0.00')
    
    def create_transaction(self, transaction_date: datetime, description: str, entries: List[JournalEntryData]):
        """–°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é"""
        if self.status != "":
            raise ValueError("Transaction already exists")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–≤–æ–π–Ω–æ–π –∑–∞–ø–∏—Å–∏
        total_debit = sum(entry.debit for entry in entries)
        total_credit = sum(entry.credit for entry in entries)
        
        if total_debit != total_credit:
            raise ValueError(f"Unbalanced transaction: debit={total_debit}, credit={total_credit}")
        
        self.raise_event("TransactionCreated", {
            "transaction_date": transaction_date.isoformat(),
            "description": description,
            "entries": [
                {
                    "account_id": str(entry.account_id),
                    "debit": str(entry.debit),
                    "credit": str(entry.credit),
                    "description": entry.description
                }
                for entry in entries
            ],
            "total_amount": str(total_debit)
        })
    
    def approve_transaction(self, approved_by: uuid.UUID):
        """–û–¥–æ–±—Ä–∏—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é"""
        if self.status != "draft":
            raise ValueError(f"Cannot approve transaction with status: {self.status}")
        
        self.raise_event("TransactionApproved", {
            "approved_by": str(approved_by),
            "approved_at": datetime.utcnow().isoformat()
        })
    
    def post_transaction(self, posted_by: uuid.UUID):
        """–ü—Ä–æ–≤–µ—Å—Ç–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é"""
        if self.status != "approved":
            raise ValueError(f"Cannot post transaction with status: {self.status}")
        
        self.raise_event("TransactionPosted", {
            "posted_by": str(posted_by),
            "posted_at": datetime.utcnow().isoformat()
        })
    
    def _apply_event(self, event: DomainEvent):
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ –∫ —Å–æ—Å—Ç–æ—è–Ω–∏—é —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
        if event.event_type == "TransactionCreated":
            self.transaction_date = datetime.fromisoformat(event.event_data["transaction_date"])
            self.description = event.event_data["description"]
            self.entries = [
                JournalEntryData(
                    account_id=uuid.UUID(entry["account_id"]),
                    debit=Decimal(entry["debit"]),
                    credit=Decimal(entry["credit"]),
                    description=entry["description"]
                )
                for entry in event.event_data["entries"]
            ]
            self.total_debit = self.total_credit = Decimal(event.event_data["total_amount"])
            self.status = "draft"
            
        elif event.event_type == "TransactionApproved":
            self.status = "approved"
            
        elif event.event_type == "TransactionPosted":
            self.status = "posted"
```

### 2.2 CQRS Implementation (–ú–µ—Å—è—Ü 8)

#### Command –∏ Query —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
```python
# new_system/cqrs/commands.py
from dataclasses import dataclass
from abc import ABC, abstractmethod

class Command(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∫–æ–º–∞–Ω–¥"""
    pass

class CommandHandler(ABC):
    @abstractmethod
    async def handle(self, command: Command) -> Any:
        pass

@dataclass
class CreateTransactionCommand(Command):
    transaction_date: datetime
    description: str
    entries: List[JournalEntryData]
    created_by: uuid.UUID

class CreateTransactionHandler(CommandHandler):
    def __init__(self, event_store: EventStore, event_bus: EventBus):
        self.event_store = event_store
        self.event_bus = event_bus
    
    async def handle(self, command: CreateTransactionCommand) -> uuid.UUID:
        # –°–æ–∑–¥–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ç
        transaction_id = uuid.uuid4()
        transaction = AccountingTransaction(transaction_id)
        
        # –í—ã–ø–æ–ª–Ω–∏—Ç—å –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É
        transaction.create_transaction(
            command.transaction_date,
            command.description,
            command.entries
        )
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–±—ã—Ç–∏—è
        await self.event_store.save_events(
            transaction.id,
            transaction.uncommitted_events,
            expected_version=0
        )
        
        # –û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏—è
        for event in transaction.uncommitted_events:
            await self.event_bus.publish(event)
        
        transaction.mark_events_as_committed()
        return transaction.id
```

#### Query side (Read Models)
```python
# new_system/cqrs/queries.py
@dataclass
class AccountBalanceQuery:
    account_id: uuid.UUID
    as_of_date: Optional[datetime] = None

class AccountBalanceQueryHandler:
    def __init__(self, read_db_pool):
        self.read_db = read_db_pool
    
    async def handle(self, query: AccountBalanceQuery) -> Decimal:
        async with self.read_db.acquire() as conn:
            if query.as_of_date:
                result = await conn.fetchval(
                    """
                    SELECT balance FROM account_balances_history 
                    WHERE account_id = $1 AND date <= $2 
                    ORDER BY date DESC LIMIT 1
                    """,
                    query.account_id,
                    query.as_of_date
                )
            else:
                result = await conn.fetchval(
                    "SELECT current_balance FROM account_balances WHERE account_id = $1",
                    query.account_id
                )
            
            return Decimal(str(result or '0.00'))

# Projection –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è read models
class AccountBalanceProjection:
    def __init__(self, read_db_pool):
        self.read_db = read_db_pool
    
    async def handle_transaction_posted(self, event: DomainEvent):
        """–û–±–Ω–æ–≤–∏—Ç—å –±–∞–ª–∞–Ω—Å—ã —Å—á–µ—Ç–æ–≤ –ø—Ä–∏ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""
        entries = event.event_data["entries"]
        
        async with self.read_db.acquire() as conn:
            async with conn.transaction():
                for entry_data in entries:
                    account_id = uuid.UUID(entry_data["account_id"])
                    debit = Decimal(entry_data["debit"])
                    credit = Decimal(entry_data["credit"])
                    
                    # –û–±–Ω–æ–≤–∏—Ç—å —Ç–µ–∫—É—â–∏–π –±–∞–ª–∞–Ω—Å
                    await conn.execute(
                        """
                        INSERT INTO account_balances (account_id, current_balance, last_updated)
                        VALUES ($1, $2, $3)
                        ON CONFLICT (account_id) DO UPDATE SET
                            current_balance = account_balances.current_balance + $2,
                            last_updated = $3
                        """,
                        account_id,
                        debit - credit,
                        event.timestamp
                    )
                    
                    # –î–æ–±–∞–≤–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –∑–∞–ø–∏—Å—å
                    await conn.execute(
                        """
                        INSERT INTO account_balance_history 
                        (account_id, date, balance_change, running_balance, transaction_id)
                        VALUES ($1, $2, $3, 
                            (SELECT current_balance FROM account_balances WHERE account_id = $1),
                            $4)
                        """,
                        account_id,
                        event.timestamp.date(),
                        debit - credit,
                        event.aggregate_id
                    )
```

### 2.3 Kafka Integration (–ú–µ—Å—è—Ü 9)

#### Event Bus —Å Kafka
```python
# new_system/infrastructure/event_bus.py
from aiokafka import AIOKafkaProducer, AIOKafkaConsumer
import json
from typing import Dict, Callable

class KafkaEventBus:
    def __init__(self, bootstrap_servers: str):
        self.bootstrap_servers = bootstrap_servers
        self.producer: Optional[AIOKafkaProducer] = None
        self.consumer: Optional[AIOKafkaConsumer] = None
        self.handlers: Dict[str, List[Callable]] = {}
    
    async def start(self):
        self.producer = AIOKafkaProducer(
            bootstrap_servers=self.bootstrap_servers,
            value_serializer=lambda v: json.dumps(v, default=str).encode('utf-8')
        )
        await self.producer.start()
    
    async def publish(self, event: DomainEvent):
        """–û–ø—É–±–ª–∏–∫–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ"""
        topic = f"accounting.{event.event_type.lower()}"
        
        event_payload = {
            "event_id": str(event.event_id),
            "aggregate_id": str(event.aggregate_id),
            "event_type": event.event_type,
            "event_data": event.event_data,
            "version": event.version,
            "timestamp": event.timestamp.isoformat(),
            "metadata": event.metadata
        }
        
        await self.producer.send(topic, event_payload)
        
        logger.info(
            "Event published",
            event_type=event.event_type,
            aggregate_id=str(event.aggregate_id),
            topic=topic
        )
    
    async def subscribe(self, event_type: str, handler: Callable):
        """–ü–æ–¥–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è"""
        if event_type not in self.handlers:
            self.handlers[event_type] = []
        self.handlers[event_type].append(handler)
    
    async def start_consuming(self):
        """–ù–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–æ–±—ã—Ç–∏–π"""
        topics = [f"accounting.{event_type.lower()}" for event_type in self.handlers.keys()]
        
        self.consumer